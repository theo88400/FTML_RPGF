{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On souhaite une configuration où le predicteur de Bayes est différent selon l'utilisation de la square loss ou de l'absolute loss.\n",
    "On a vu que le prédicteur de Bayes dans le cas de la square loss est l'espérence conditionnelle de Y sachant X.\n",
    "Dans le cas de l'absolute loss, c'est la médiane de Y sachant X.\n",
    "\n",
    "On veut donc prendre une loi de probabilité selon laquelle la médiane est différente de l'espérence.\n",
    "\n",
    "Soit la modelisation suivante : <br>\n",
    "X suit une loi uniforme sur [0.1; 0.9]. <br>\n",
    "Y suit une loi géomètrique de paramètre(X).\n",
    "\n",
    "Pour la square loss: \n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "f^*(x) & = E[Y|X] \\\\\n",
    "& = 1/X \n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "R(f^*(x)) & = E_{X, Y}[l(y, f^*(x))] \\\\\n",
    "& = E_X[E_Y[l(y, f^*(x)) | X = x]] \\\\\n",
    "& = E_X[E_Y[(y - \\frac{1}{x})^2 | X = x]] \\\\\n",
    "& = E_X[\\sum_{y=1}^{+\\infty} (y - \\frac{1}{x})^2 (1-x)^{y-1}x] \\\\\n",
    "& = \\int_{0.1}^{0.9}(\\sum_{y=1}^{+\\infty} (y - \\frac{1}{x})^2 (1-x)^{y-1}x)\\frac{1}{0.9 - 0.1}dx \\\\\n",
    "\\end{split}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant Wolframe alpha on calcule le Risk De bayes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Bayes Risk for square loss](./images/squareloss_bayes_risk.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour la absolute loss :\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "f^*(x) & = Mediane Y|X \\\\\n",
    "& = \\lceil{\\frac{-log(2)}{log(1-X)}} \\rceil\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "R(f^*(x)) & = E_{X, Y}[l(y, f^*(x))] \\\\\n",
    "& = E_X[E_Y[l(y, f^*(x)) | X = x]] \\\\\n",
    "& = E_X[E_Y[|y - \\lceil{\\frac{-log(2)}{log(1-X)}} \\rceil| | X = x]] \\\\\n",
    "& = E_X[\\sum_{y=1}^{+\\infty} |y - \\lceil{\\frac{-log(2)}{log(1-X)}} \\rceil| P(Y = y | X = x)] \\\\\n",
    "& = E_X[\\sum_{y=1}^{\\lfloor(\\frac{1}{x})} (\\lceil{\\frac{-log(2)}{log(1-X)}} \\rceil - y) P(Y = y | X = x)\n",
    "+\n",
    "\\sum_{y=\\lfloor \\frac{1}{x} \\rfloor}^{+\\infty} (y - \\lceil{\\frac{-log(2)}{log(1-X)}} \\rceil) P(Y = y | X = x)\n",
    "] \\\\\n",
    "& = \\int_{0.1}^{0.9}(\\sum_{y=1}^{\\lfloor(\\frac{1}{x})} (\\lceil{\\frac{-log(2)}{log(1-X)}} \\rceil - y) (1-x)^{y-1}x\n",
    "+\n",
    "\\sum_{y=\\lfloor \\frac{1}{x} \\rfloor}^{+\\infty} (y - \\lceil{\\frac{-log(2)}{log(1-X)}} \\rceil) (1-x)^{y-1}x)\\frac{1}{0.9 - 0.1}dx \\\\\n",
    "\\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous essayons de calculer avec Wolframe alpha mais le calcul étant trop complexe nous ne parvenons pas à le calculer avec la version gratuite de Wolframe Alpha"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Bayes Risk with the absolute loss and the bayes predictor](images/absoluteloss_with_median_bayes_risk.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cependant, étrangement le calcul se fait lorsque l'on utilise l'esperance Y sachant X, c'est à dire ici $ \\frac{1}{x} $ comme prédicteur. On vérifiera alors ce calcul expérimentalement."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Bayes Risk with absolute loss and E[Y|X] predictor](images/absoluteloss_with_expected_bayes_predictor.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the loss functions\n",
    "def square_loss(x , y) -> float:\n",
    "    return (x - y)**2\n",
    "\n",
    "def absolute_loss(x , y) -> float:\n",
    "    return np.abs(x - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the data\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def generate_data(n_samples: int) -> Tuple[np.array, np.array]:\n",
    "    \"\"\"\n",
    "    n_samples: number of samples to generate\n",
    "    return: X, Y\n",
    "    \"\"\"\n",
    "    X = rng.uniform(0.1, 0.9, size=n_samples) # we restrict the range to avoid 0 and 1 and to explode the loss\n",
    "    Y = rng.geometric(X) # Y follows a geometric distribution with parameter X\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the bayes predictor for the square loss\n",
    "# which is the conditional expectation\n",
    "def square_bayes_predictor(X: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    It generates the prediction for the bayes predictor which is the conditional expectation.\n",
    "    Here it's 1/X because Y follows geometric distribution with parameter X.\n",
    "    \"\"\"\n",
    "    return 1/X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the bayes predictor for the absolute loss\n",
    "# which is the median\n",
    "\n",
    "def absolute_bayes_predictor(X: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    It generates the prediction for the bayes predictor which is the median.\n",
    "    Here it's supp(-ln(2) / ln(q))) where q = 1 - X.\n",
    "    https://fr.wikipedia.org/wiki/Loi_g%C3%A9om%C3%A9trique\n",
    "    \"\"\"\n",
    "    return np.ceil((- np.log(2)) / np.log(1 - X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a bad estimator to compare results\n",
    "def bad_estimator(X: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    X: np.array of inputs\n",
    "    Given a set of inputs, return a bad estimator\n",
    "    \"\"\"\n",
    "\n",
    "    return rng.geometric(0.5, size=len(X)) # random estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the empirical risk function\n",
    "def empirical_risk(estimator, loss, X: np.array, Y: np.array) -> float:\n",
    "    \"\"\"\n",
    "    estimator: function that takes X and returns Y\n",
    "    loss: function that takes two values and returns a loss\n",
    "    X: np.array of inputs\n",
    "    Y: np.array of outputs\n",
    "    Given a set of inputs and outputs, return the empirical risk\n",
    "    \"\"\"\n",
    "\n",
    "    Y_pred = estimator(X)\n",
    "    l = loss(Y, Y_pred)\n",
    "    return l.mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X =  [0.51081115 0.7662838  0.35429327 ... 0.11382151 0.12447091 0.10446652]\n",
      "Y =  [1 1 2 ... 9 1 5]\n",
      "\n",
      "with the square loss\n",
      "Empirical risk for the bad estimator:  14.712686\n",
      "Empirical risk for the squared bayes predictor:  8.497643756298206\n",
      "Empirical risk for the absolute bayes predictor:  9.460232\n",
      "\n",
      "with the absolute loss\n",
      "Empirical risk for the bad estimator:  2.021086\n",
      "Empirical risk for the squared bayes predictor:  1.585885175370916\n",
      "Empirical risk for the absolute bayes predictor:  1.438746\n"
     ]
    }
   ],
   "source": [
    "X, Y = generate_data(int(1e6))\n",
    "print('X = ', X)\n",
    "print(\"Y = \", Y)\n",
    "print(\"\")\n",
    "\n",
    "print(\"with the square loss\")\n",
    "print(\"Empirical risk for the bad estimator: \", empirical_risk(bad_estimator, square_loss, X, Y))\n",
    "print(\"Empirical risk for the squared bayes predictor: \", empirical_risk(square_bayes_predictor, square_loss, X, Y))\n",
    "print(\"Empirical risk for the absolute bayes predictor: \", empirical_risk(absolute_bayes_predictor, square_loss, X, Y))\n",
    "print(\"\")\n",
    "print(\"with the absolute loss\")\n",
    "print(\"Empirical risk for the bad estimator: \", empirical_risk(bad_estimator, absolute_loss, X, Y))\n",
    "print(\"Empirical risk for the squared bayes predictor: \", empirical_risk(square_bayes_predictor, absolute_loss, X, Y))\n",
    "print(\"Empirical risk for the absolute bayes predictor: \", empirical_risk(absolute_bayes_predictor, absolute_loss, X, Y))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour la square loss, on a bien les deux estimateur de bayes qui sont meilleurs que l'estimateur aléatoire. \n",
    "<br>\n",
    "<br>\n",
    "De plus, comme prévu le squared bayes predictor a un risque empirique plus faible que l'absolute bayes predictor confirmant qu'il est meilleur lorsque l'on utilise la squared loss. <br>\n",
    "Enfin, 8.49 est proche de la valeur théorique 8.36 que l'on cherchait à estimer\n",
    "\n",
    "Pour la absolute loss, on retrouve les mêmes conclusions attendues. L'absolute bayes predictor a un risque empirique plus faible que le squared bayes predictor confirmant qu'il est meilleur lorsque l'on considère l'absolute loss.\n",
    "On retrouve également le résultat théorique attendu, à savoir 1.58 contre 1.57 pour le risque empirique du prédicteur E[Y|X] avec l'absolute loss.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    " f^*(x) & = arg min E[|y − z||X = x] \\\\\n",
    " E[|y − z||X = x] & = \\int_{-\\infty}^{+\\infty} |y - z| p_{Y|X=x}dy \\\\\n",
    " & = \\int_{-\\infty}^{z} (z - y)p_{Y|X=x}dy + \\int_{z}^{+\\infty} (y - z)p_{Y|X=x}dy \\\\\n",
    " & = \\int_{-\\infty}^{z} -(y - z)p_{Y|X=x}dy + \\int_{z}^{+\\infty} (y - z)p_{Y|X=x}dy \\\\ \n",
    " \\end{split}\n",
    " \\end{equation}\n",
    "$\n",
    "Pour trouver le minimum, on va chercher quand est-ce que la dérivée s'annule.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\frac{\\partial E[|y − z||X = x]}{\\partial z} & = \\int_{-\\infty}^{z} p_{Y|X=x}dy + \\int_{z}^{+\\infty} -p_{Y|X=x}dy = 0 \\\\\n",
    "\\int_{-\\infty}^{z} p_{Y|X=x}dy & = \\int_{z}^{+\\infty} -p_{Y|X=x}dy \\\\\n",
    "\\implies 2 * \\int_{-\\infty}^{z} p_{Y|X=x}dy & = \\int_{-\\infty}^{+\\infty} p_{Y|X=x}dy = 1 \\\\\n",
    "\\int_{-\\infty}^{z} p_{Y|X=x}dy & = \\frac{1}{2} \\\\\n",
    "\\text{Donc } F_{Y|X}(z) = \\frac{1}{2} \\\\ \\\\\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "Vérifions que c'est bien un minimum\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\frac{\\partial E[|y − z||X = x]}{\\partial z}  = \\int_{-\\infty}^{z} p_{Y|X=x}dy - \\int_{z}^{+\\infty} p_{Y|X=x}dy & < 0 \\\\\n",
    "F_{Y|X}(z) - (1 - F_{Y|X}(z)) < 0 \\\\\n",
    "2*F_{Y|X}(z) < 1 \\\\\n",
    "F_{Y|X}(z) < \\frac{1}{2} \\\\\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "F_{Y|X} est une fonction de répartition donc elle est croissante sur l'intervalle [0, 1]. On peut donc tracer le tableau de variation suivant."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Tableau de variation](images/tableau_variation.jpeg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\text{Donc } z = f^{*}(x) \\text{ est la médiane de Y sachant X}\n",
    "$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_python_FTML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
